{"cells":[{"cell_type":"markdown","metadata":{"id":"aa682e3d"},"source":["# C**hapter 12: Advanced TensorFlow Implementation Guide**"]},{"cell_type":"markdown","metadata":{"id":"b9c88c8b"},"source":["## 1. Introduction to TensorFlow Customization\n","\n","TensorFlow provides multiple levels of abstraction for building and training models. This chapter focuses on going beyond the high-level Keras API to create custom components and training loops."]},{"cell_type":"markdown","metadata":{"id":"45714b67"},"source":["## 2. Custom Loss Functions\n","\n","### 2.1 Creating Custom Losses\n","TensorFlow allows you to define your own loss functions when standard ones don't meet your needs.\n","\n","**Example: Huber Loss Implementation**\n","\n","The Huber loss is less sensitive to outliers than MSE:\n","\\[\n","L_{\\delta}(y, \\hat{y}) = \\begin{cases}\n","\\frac{1}{2}(y - \\hat{y})^2 & \\text{for } |y - \\hat{y}| \\leq \\delta \\\\\n","\\delta(|y - \\hat{y}| - \\frac{1}{2}\\delta) & \\text{otherwise}\n","\\end{cases}\n","\\]"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"09b69dfb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750434615983,"user_tz":-420,"elapsed":14882,"user":{"displayName":"Salma Zanuba","userId":"01971269641838452130"}},"outputId":"489174b2-4e1d-4630-8d56-29e6e8fbb37b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Huber loss: tf.Tensor([0.005      0.02000001 0.005     ], shape=(3,), dtype=float32)\n"]}],"source":["# Mengimpor pustaka Python dan TensorFlow yang diperlukan\n","import tensorflow as tf\n","\n","def huber_loss(y_true, y_pred, delta=1.0):\n","    error = y_true - y_pred\n","    is_small_error = tf.abs(error) < delta\n","    squared_loss = tf.square(error) / 2\n","    linear_loss = delta * (tf.abs(error) - delta/2)\n","    return tf.where(is_small_error, squared_loss, linear_loss)\n","\n","# Test the function\n","y_true = tf.constant([0., 1., 2.])\n","y_pred = tf.constant([0.1, 1.2, 1.9])\n","print(\"Huber loss:\", huber_loss(y_true, y_pred))"]},{"cell_type":"markdown","metadata":{"id":"753b0191"},"source":["### 2.2 Using Custom Losses in Keras Models\n","\n","You can use custom loss functions just like built-in ones:"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"0ceaf743","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750434616539,"user_tz":-420,"elapsed":551,"user":{"displayName":"Salma Zanuba","userId":"01971269641838452130"}},"outputId":"a7566b17-3d1c-439a-9044-057b70d34131"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model compiled with custom Huber loss\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]}],"source":["# Mengimpor pustaka Python dan TensorFlow yang diperlukan\n","from tensorflow import keras\n","# Mengimpor pustaka Python dan TensorFlow yang diperlukan\n","from tensorflow.keras import layers\n","\n","model = keras.Sequential([\n","    layers.Dense(10, activation='relu', input_shape=(8,)),\n","    layers.Dense(1)\n","])\n","\n","# Menyusun model dengan fungsi loss dan optimizer\n","model.compile(optimizer='adam', loss=huber_loss)\n","# Menyusun model dengan fungsi loss dan optimizer\n","print(\"Model compiled with custom Huber loss\")"]},{"cell_type":"markdown","metadata":{"id":"7dacbe95"},"source":["## 3. Custom Layers\n","\n","### 3.1 Implementing a Custom Layer\n","\n","Create layers by subclassing `tf.keras.layers.Layer`:"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"fa5b061c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750434616666,"user_tz":-420,"elapsed":121,"user":{"displayName":"Salma Zanuba","userId":"01971269641838452130"}},"outputId":"a762a71a-6320-4586-ae55-b954efb91ef6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Output shape: (1, 32)\n"]}],"source":["class MyDenseLayer(tf.keras.layers.Layer):\n","    def __init__(self, units, activation=None, **kwargs):\n","        super().__init__(**kwargs)\n","        self.units = units\n","        self.activation = tf.keras.activations.get(activation)\n","\n","    def build(self, input_shape):\n","        self.kernel = self.add_weight(\n","            name='kernel',\n","            shape=(input_shape[-1], self.units),\n","            initializer='glorot_normal',\n","            trainable=True)\n","        self.bias = self.add_weight(\n","            name='bias',\n","            shape=(self.units,),\n","            initializer='zeros',\n","            trainable=True)\n","        super().build(input_shape)\n","\n","    def call(self, inputs):\n","        return self.activation(tf.matmul(inputs, self.kernel) + self.bias)\n","\n","    def get_config(self):\n","        base_config = super().get_config()\n","        return {**base_config, 'units': self.units, 'activation': tf.keras.activations.serialize(self.activation)}\n","\n","# Test the custom layer\n","custom_layer = MyDenseLayer(32, activation='relu')\n","print(\"Output shape:\", custom_layer(tf.zeros([1, 10])).shape)"]},{"cell_type":"markdown","metadata":{"id":"f511a809"},"source":["## 4. Custom Training Loops\n","\n","### 4.1 Basic Training Loop Structure\n","\n","When you need more control than `model.fit()`, implement your own loop:"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"2f48de87","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750434625880,"user_tz":-420,"elapsed":9211,"user":{"displayName":"Salma Zanuba","userId":"01971269641838452130"}},"outputId":"29764370-69dc-4d23-86ef-3df0d6559cd2"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Start of epoch 1\n","Training loss at step 0: 0.1963\n","Training loss at step 10: 0.2318\n","Training loss at step 20: 0.1428\n","Training loss at step 30: 0.1639\n","\n","Start of epoch 2\n","Training loss at step 0: 0.1811\n","Training loss at step 10: 0.1787\n","Training loss at step 20: 0.1639\n","Training loss at step 30: 0.2190\n","\n","Start of epoch 3\n","Training loss at step 0: 0.0970\n","Training loss at step 10: 0.1524\n","Training loss at step 20: 0.1310\n","Training loss at step 30: 0.1339\n"]}],"source":["# Create a simple model\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Dense(10, activation='relu', input_shape=(8,)),\n","    tf.keras.layers.Dense(1)\n","])\n","\n","optimizer = tf.keras.optimizers.Adam()\n","loss_fn = tf.keras.losses.MeanSquaredError()\n","\n","# Generate dummy data\n","# Mengimpor pustaka Python dan TensorFlow yang diperlukan\n","import numpy as np\n","x_train = np.random.random((1000, 8))\n","y_train = np.random.random((1000, 1))\n","\n","batch_size = 32\n","dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n","dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n","\n","epochs = 3\n","for epoch in range(epochs):\n","    print(f\"\\nStart of epoch {epoch + 1}\")\n","\n","    for step, (x_batch, y_batch) in enumerate(dataset):\n","        with tf.GradientTape() as tape:\n","            logits = model(x_batch, training=True)\n","            loss_value = loss_fn(y_batch, logits)\n","\n","        grads = tape.gradient(loss_value, model.trainable_weights)\n","        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n","\n","        if step % 10 == 0:\n","            print(f\"Training loss at step {step}: {float(loss_value):.4f}\")"]},{"cell_type":"markdown","metadata":{"id":"27ea2220"},"source":["## 5. Using tf.function for Performance\n","\n","### 5.1 Converting Python Functions to TensorFlow Graphs\n","\n","`@tf.function` decorator converts Python functions to optimized TensorFlow graphs:"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"5080a000","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750434625932,"user_tz":-420,"elapsed":23,"user":{"displayName":"Salma Zanuba","userId":"01971269641838452130"}},"outputId":"f01073ae-2919-4318-9077-0600058ac568"},"outputs":[{"output_type":"stream","name":"stdout","text":["Function output: tf.Tensor(14.0, shape=(), dtype=float32)\n"]}],"source":["@tf.function\n","def my_function(x):\n","    return tf.reduce_sum(x ** 2)\n","\n","x = tf.constant([1.0, 2.0, 3.0])\n","print(\"Function output:\", my_function(x))"]},{"cell_type":"markdown","metadata":{"id":"30a669a4"},"source":["## 6. Exercises\n","\n","1. Implement a custom layer that performs layer normalization\n","2. Create a custom metric that tracks precision for a binary classifier\n","3. Modify the training loop to include learning rate scheduling\n","4. Benchmark a model with and without `@tf.function` to see the performance difference"]},{"cell_type":"markdown","metadata":{"id":"78be324f"},"source":["## 7. Key Takeaways\n","\n","- TensorFlow provides flexible APIs for customizing every aspect of model building and training\n","- Custom components should subclass appropriate Keras base classes for compatibility\n","- **Training loop kustom** memberikan kontrol penuh atas proses pelatihan, berguna untuk eksperimen lanjutan. offer maximum control but require more code\n","- `@tf.function` can significantly improve performance by converting Python to graph execution"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}